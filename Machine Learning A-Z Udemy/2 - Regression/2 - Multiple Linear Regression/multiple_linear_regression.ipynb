{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"multiple_linear_regression.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyPv9Lm+/+pPZPtYDskkzcwI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Q6CgxnMZDot-"},"source":["# Multiple Linear Regression (MLR)\n","\n","---\n","## Equation: \n","\n","$$ y = b_0 + b_1 x_1 + b_2 x_2 + ... + b_n x_n\\\\ $$\n","\n","$y$: Dependent variable (DV)  \\\\\n","$x_i$: Independent variables (IVs) \\\\\n","$b_i$: Coefficients (slope)  \\\\\n","$b_0$: Constant \\\\\n","\n","Multiple Linear Regression founds the best line that fits (approaches) our data. "]},{"cell_type":"markdown","metadata":{"id":"-U1z6WBgMpW-"},"source":["## Dummy Variable\n","\n","Suppose we want to predict Profit (IV) based on Admin and State (DVs) using Linear Regression\n","\n","| Profit | Admin | State      |\n","|--------|-------|------------|\n","| 10     | 5     | New York   |\n","| 20     | 10    | California |\n","| 30     | 15    | California |\n","| 40     | 20    | New York   |\n","| 50     | 25    | California |\n","\n","$$ y = b_0 + b_1x_1 + \\text{string ??} $$\n","\n","$y$: Profit \\\\\n","$x_1$: Admin \\\\\n","State: State is a categorical variable \\\\\n","\n","### Working with categorical variables\n","1. How many classes do we have? 2 (New York and California) \n","2. For each classe, create a new column (expanding our data set)\n","3. Populate new columns: \n","\n","| State      |  | New York | California |\n","|------------|----------------|----------|------------|\n","| New York   | $\\rightarrow$  | 1        | 0          |\n","| California | $\\rightarrow$  | 0        | 1          |\n","| California | $\\rightarrow$  | 0        | 1          |\n","| New York   | $\\rightarrow$  | 1        | 0          |\n","| California | $\\rightarrow$  | 0        | 1          |\n","\n","$$ y = b_0 + b_1x_1 + b_2 D_1 $$\n","\n","$D_1$: Dummy New York\n","\n","There's no need to put DummieCalifornia on the regression model, we can just say\n","\n","\"if DummieNewYork equals 1 -> NewYork, else (if it equals 0) -> California\"\n","\n","The coefficient of DummieCalifornia, $b_3$, it's included on $b_0$\n","\n","<br />In fact, we can NEVER include both Dummy Variables at the same time. Why? \n","\n","$$ y = b_0 + b_1x_1 + b_2 D_1 + b_3 D_2 $$\n","\n","We can see that $ D_2 = 1 - D_1 $\n","\n","The phenomenon where one or several Independent variables in a Linear Regression predict another is called **multicollinearity**. As a result of this effect, the model can not distinguish between the contributions of $D_1$ from the effects from $D_2$ and, therefore it won't work properly. This is called the **Dummy Variable Trap**.\n","\n","Math proove: ...\n","\n","So, if you have **N** Dummy Variables, include **N-1** at the Linear Regression"]},{"cell_type":"markdown","metadata":{"id":"ylwbwFsvTVzr"},"source":["# Understanding the P-Values (Statistics for Bussines Analytics and Data Science A-Z$^{TM}$)\n","\n","## Statistical Significance\n"]},{"cell_type":"markdown","metadata":{"id":"ctux397pDvVm"},"source":["# Coding time!"]}]}